@misc{Pancreas,
    author = {Longnecker, Daniel.},
	doi = {10.3998/panc.2014.3},
    year = {2014},
	url = {https://doi.org/10.3998%2Fpanc.2014.3},
	publisher = {University of Michigan Library},
	title = {Anatomy and Histology of the Pancreas}
}

@Article{pmid18787611,
   Author="Hruban, R. H.  and Maitra, A.  and Goggins, M. ",
   Title="{{U}pdate on pancreatic intraepithelial neoplasia}",
   Journal="Int J Clin Exp Pathol",
   Year="2008",
   Volume="1",
   Number="4",
   Pages="306--316",
   Month="Jan"
}

@book{oliphant2006guide,
 title={A guide to NumPy},
 author={Oliphant, Travis E},
 volume={1},
 year={2006},
 publisher={Trelgol Publishing USA}
}

@inproceedings{10.1145/1553374.1553380,
    author = {Bengio, Yoshua and Louradour, J\'{e}r\^{o}me and Collobert, Ronan and Weston, Jason},
    title = {Curriculum Learning},
    year = {2009},
    isbn = {9781605585161},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/1553374.1553380},
    doi = {10.1145/1553374.1553380},
    abstract = {Humans and animals learn much better when the examples are not randomly presented but organized in a meaningful order which illustrates gradually more concepts, and gradually more complex ones. Here, we formalize such training strategies in the context of machine learning, and call them "curriculum learning". In the context of recent research studying the difficulty of training in the presence of non-convex training criteria (for deep deterministic and stochastic neural networks), we explore curriculum learning in various set-ups. The experiments show that significant improvements in generalization can be achieved. We hypothesize that curriculum learning has both an effect on the speed of convergence of the training process to a minimum and, in the case of non-convex criteria, on the quality of the local minima obtained: curriculum learning can be seen as a particular form of continuation method (a general strategy for global optimization of non-convex functions).},
    booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
    pages = {41–48},
    numpages = {8},
    location = {Montreal, Quebec, Canada},
    series = {ICML '09}
}

@article{ravindran2018classification,
  title={Classification of CITES-listed and other neotropical Meliaceae wood images using convolutional neural networks},
  author={Ravindran, Prabu and Costa, Adriana and Soares, Richard and Wiedenhoeft, Alex C},
  journal={Plant methods},
  volume={14},
  number={1},
  pages={1--10},
  year={2018},
  publisher={BioMed Central}
}

@incollection{alheejawi2020deep,
  title={Deep learning-based histopathological image analysis for automated detection and staging of melanoma},
  author={Alheejawi, Salah and Mandal, Mrinal and Xu, Hongming and Lu, Cheng and Berendt, Richard and Jha, Naresh},
  booktitle={Deep Learning Techniques for Biomedical and Health Informatics},
  pages={237--265},
  year={2020},
  publisher={Elsevier}
}

@article{Senaras2018,
  doi = {10.1371/journal.pone.0196846},
  url = {https://doi.org/10.1371/journal.pone.0196846},
  year = {2018},
  month = may,
  publisher = {Public Library of Science ({PLoS})},
  volume = {13},
  number = {5},
  pages = {e0196846},
  author = {Caglar Senaras and Muhammad Khalid Khan Niazi and Berkman Sahiner and Michael P. Pennell and Gary Tozbikian and Gerard Lozanski and Metin N. Gurcan},
  editor = {Chandan Kumar-Sinha},
  title = {Optimized generation of high-resolution phantom images using {cGAN}: Application to quantification of Ki67 breast cancer images},
  journal = {{PLOS} {ONE}}
}

@inproceedings{10.1117/12.2254452,
author = {Bassem Ben Cheikh and Catherine Bor-Angelier and Daniel Racoceanu},
title = {{A model of tumor architecture and spatial interactions with tumor microenvironment in breast carcinoma}},
volume = {10140},
booktitle = {Medical Imaging 2017: Digital Pathology},
editor = {Metin N. Gurcan and John E. Tomaszewski},
organization = {International Society for Optics and Photonics},
publisher = {SPIE},
pages = {73 -- 80},
keywords = {Breast carcinoma architecture, Tumor microenvironment, Spatial arrangement, Modeling and simulation, Mathematical Morphology},
year = {2017},
doi = {10.1117/12.2254452},
URL = {https://doi.org/10.1117/12.2254452}
}

@INPROCEEDINGS{5206848,
  author={J. {Deng} and W. {Dong} and R. {Socher} and L. {Li} and  {Kai Li} and  {Li Fei-Fei}},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition},
  title={ImageNet: A large-scale hierarchical image database},
  year={2009},
  volume={},
  number={},
  pages={248-255}
}

@article{Alturkistani2015,
  doi = {10.5539/gjhs.v8n3p72},
  url = {https://doi.org/10.5539/gjhs.v8n3p72},
  year = {2015},
  month = jun,
  publisher = {Canadian Center of Science and Education},
  volume = {8},
  number = {3},
  pages = {72},
  author = {Hani A Alturkistani and Faris M Tashkandi and Zuhair M Mohammedsaleh},
  title = {Histological Stains: A Literature Review and Case Study},
  journal = {Global Journal of Health Science}
}

@article{Rosai2007,
  doi = {10.1038/labinvest.3700551},
  url = {https://doi.org/10.1038/labinvest.3700551},
  year = {2007},
  month = apr,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {87},
  number = {5},
  pages = {403--408},
  author = {Juan Rosai},
  title = {Why microscopy will remain a cornerstone of surgical pathology},
  journal = {Laboratory Investigation}
}

@article{he_stain,
author = {M Titford},
title = {The long history of hematoxylin},
journal = {Biotechnic \& Histochemistry},
volume = {80},
number = {2},
pages = {73-78},
year  = {2005},
publisher = {Taylor & Francis},
doi = {10.1080/10520290500138372},
URL = {https://doi.org/10.1080/10520290500138372},
eprint = {https://doi.org/10.1080/10520290500138372}
}

@article{WSI_grid,
author = {Cruz-Roa, Angel and Basavanhally, Ajay and González, Fabio and Gilmore, Hannah and Feldman, Michael and Ganesan, Shridar and Shih, Natalie and Tomaszewski, John and Madabhushi, Anant},
year = {2014},
month = {02},
pages = {},
title = {Automatic detection of invasive ductal carcinoma in whole slide images with Convolutional Neural Networks},
volume = {9041},
journal = {Progress in Biomedical Optics and Imaging - Proceedings of SPIE},
doi = {10.1117/12.2043872}
}

@misc{1611.07004,
Author = {Phillip Isola and Jun-Yan Zhu and Tinghui Zhou and Alexei A. Efros},
Title = {Image-to-Image Translation with Conditional Adversarial Networks},
Year = {2016},
Eprint = {arXiv:1611.07004},
}

@misc{1901.06656,
Author = {Arild Nøkland and Lars Hiller Eidnes},
Title = {Training Neural Networks with Local Error Signals},
Year = {2019},
Eprint = {arXiv:1901.06656},
}

@misc{1806.09077,
Author = {Anna Choromanska and Benjamin Cowen and Sadhana Kumaravel and Ronny Luss and Mattia Rigotti and Irina Rish and Brian Kingsbury and Paolo DiAchille and Viatcheslav Gurev and Ravi Tejwani and Djallel Bouneffouf},
Title = {Beyond Backprop: Online Alternating Minimization with Auxiliary Variables},
Year = {2018},
Eprint = {arXiv:1806.09077},
}

@article{10.1093/bioinformatics/bts480,
    author = {Köster, Johannes and Rahmann, Sven},
    title = "{Snakemake—a scalable bioinformatics workflow engine}",
    journal = {Bioinformatics},
    volume = {28},
    number = {19},
    pages = {2520-2522},
    year = {2012},
    month = {08},
    abstract = "{Summary: Snakemake is a workflow engine that provides a readable Python-based workflow definition language and a powerful execution environment that scales from single-core workstations to compute clusters without modifying the workflow. It is the first system to support the use of automatically inferred multiple named wildcards (or variables) in input and output filenames.Availability:http://snakemake.googlecode.com.Contact:johannes.koester@uni-due.de}",
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/bts480},
    url = {https://doi.org/10.1093/bioinformatics/bts480},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/28/19/2520/819790/bts480.pdf},
}

@article{Chouhan2018,
  doi = {10.1007/s11831-018-9257-4},
  url = {https://doi.org/10.1007/s11831-018-9257-4},
  year = {2018},
  month = feb,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {26},
  number = {3},
  pages = {533--596},
  author = {Siddharth Singh Chouhan and Ajay Kaul and Uday Pratap Singh},
  title = {Image Segmentation Using Computational Intelligence Techniques: Review},
  journal = {Archives of Computational Methods in Engineering}
}

@article{10.1145/361002.361007,
author = {Bentley, Jon Louis},
title = {Multidimensional Binary Search Trees Used for Associative Searching},
year = {1975},
issue_date = {Sept. 1975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {9},
issn = {0001-0782},
url = {https://doi.org/10.1145/361002.361007},
doi = {10.1145/361002.361007},
abstract = {This paper develops the multidimensional binary search tree (or k-d tree, where k is the dimensionality of the search space) as a data structure for storage of information to be retrieved by associative searches. The k-d tree is defined and examples are given. It is shown to be quite efficient in its storage requirements. A significant advantage of this structure is that a single data structure can handle many types of queries very efficiently. Various utility algorithms are developed; their proven average running times in an n record file are: insertion, O(log n); deletion of the root, O(n(k-1)/k); deletion of a random node, O(log n); and optimization (guarantees logarithmic performance of searches), O(n log n). Search algorithms are given for partial match queries with t keys specified [proven maximum running time of O(n(k-t)/k)] and for nearest neighbor queries [empirically observed average running time of O(log n).] These performances far surpass the best currently known algorithms for these tasks. An algorithm is presented to handle any general intersection query. The main focus of this paper is theoretical. It is felt, however, that k-d trees could be quite useful in many applications, and examples of potential uses are given.},
journal = {Commun. ACM},
month = sep,
pages = {509–517},
numpages = {9},
keywords = {information retrieval system, nearest neighbor queries, binary tree insertion, key, associative retrieval, intersection queries, binary search trees, attribute, partial match queries}
}

@ARTICLE{2020SciPy-NMeth,
       author = {{Virtanen}, Pauli and {Gommers}, Ralf and {Oliphant},
         Travis E. and {Haberland}, Matt and {Reddy}, Tyler and
         {Cournapeau}, David and {Burovski}, Evgeni and {Peterson}, Pearu
         and {Weckesser}, Warren and {Bright}, Jonathan and {van der Walt},
         St{\'e}fan J.  and {Brett}, Matthew and {Wilson}, Joshua and
         {Jarrod Millman}, K.  and {Mayorov}, Nikolay and {Nelson}, Andrew
         R.~J. and {Jones}, Eric and {Kern}, Robert and {Larson}, Eric and
         {Carey}, CJ and {Polat}, {\.I}lhan and {Feng}, Yu and {Moore},
         Eric W. and {Vand erPlas}, Jake and {Laxalde}, Denis and
         {Perktold}, Josef and {Cimrman}, Robert and {Henriksen}, Ian and
         {Quintero}, E.~A. and {Harris}, Charles R and {Archibald}, Anne M.
         and {Ribeiro}, Ant{\^o}nio H. and {Pedregosa}, Fabian and
         {van Mulbregt}, Paul and {Contributors}, SciPy 1. 0},
        title = "{SciPy 1.0: Fundamental Algorithms for Scientific
                  Computing in Python}",
      journal = {Nature Methods},
      year = "2020",
      volume={17},
      pages={261--272},
      adsurl = {https://rdcu.be/b08Wh},
      doi = {https://doi.org/10.1038/s41592-019-0686-2},
}

@misc{NEURIPS2019_9015,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@article{shanno1970conditioning,
  title={Conditioning of quasi-Newton methods for function minimization},
  author={Shanno, David F},
  journal={Mathematics of computation},
  volume={24},
  number={111},
  pages={647--656},
  year={1970}
}

@article{10.1093/imamat/6.1.76,
    author = {BROYDEN, C. G.},
    title = "{The Convergence of a Class of Double-rank Minimization Algorithms 1. General Considerations}",
    journal = {IMA Journal of Applied Mathematics},
    volume = {6},
    number = {1},
    pages = {76-90},
    year = {1970},
    month = {03},
    abstract = "{This paper presents a more detailed analysis of a class of minimization algorithms, which includes as a special case the DFP (Davidon-Fletcher-Powell) method, than has previously appeared. Only quadratic functions are considered but particular attention is paid to the magnitude of successive errors and their dependence upon the initial matrix. On the basis of this a possible explanation of some of the observed characteristics of the class is tentatively suggested.}",
    issn = {0272-4960},
    doi = {10.1093/imamat/6.1.76},
    url = {https://doi.org/10.1093/imamat/6.1.76},
    eprint = {https://academic.oup.com/imamat/article-pdf/6/1/76/2233756/6-1-76.pdf},
}

@inproceedings{imagenet_cvpr09,
        AUTHOR = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
        TITLE = {{ImageNet: A Large-Scale Hierarchical Image Database}},
        BOOKTITLE = {CVPR09},
        YEAR = {2009},
        BIBSOURCE = "http://www.image-net.org/papers/imagenet_cvpr09.bib"
}

@misc{1508.06576,
    Author = {Leon A. Gatys and Alexander S. Ecker and Matthias Bethge},
    Title = {A Neural Algorithm of Artistic Style},
    Year = {2015},
    Eprint = {arXiv:1508.06576},
}

@article{Ki67,
    author = {Niazi, Muhammad and Tavolara, Thomas and Arole, Vidya and Hartman, Douglas and Pantanowitz, Liron and Gurcan, Metin},
    year = {2018},
    month = {04},
    pages = {e0195621},
    title = {Identifying tumor in pancreatic neuroendocrine neoplasms from Ki67 images using transfer learning},
    volume = {13},
    journal = {PLOS ONE},
    doi = {10.1371/journal.pone.0195621}
}

@article{pinkus_1999,
    title={Approximation theory of the MLP model in neural networks},
    volume={8},
    DOI={10.1017/S0962492900002919},
    journal={Acta Numerica},
    publisher={Cambridge University Press}, author={Pinkus, Allan},
    year={1999},
    pages={143–195}
}

@book{10.5555/3275328,
    author = {Skansi, Sandro},
    title = {Introduction to Deep Learning: From Logical Calculus to Artificial Intelligence},
    year = {2018},
    isbn = {3319730037},
    publisher = {Springer Publishing Company, Incorporated},
    edition = {1st}
}

@misc{1803.08375,
    Author = {Abien Fred Agarap},
    Title = {Deep Learning using Rectified Linear Units (ReLU)},
    Year = {2018},
    Eprint = {arXiv:1803.08375},
}

@TECHREPORT{cifar10,
    author = {Alex Krizhevsky},
    title = {Learning multiple layers of features from tiny images},
    institution = {},
    year = {2009}
}

@misc{1412.6980,
    Author = {Diederik P. Kingma and Jimmy Ba},
    Title = {Adam: A Method for Stochastic Optimization},
    Year = {2014},
    Eprint = {arXiv:1412.6980},
}

@misc{deep_seg_SOA,
    title={Image Segmentation Using Deep Learning: A Survey},
    author={Shervin Minaee and Yuri Boykov and Fatih Porikli and Antonio Plaza and Nasser Kehtarnavaz and Demetri Terzopoulos},
    year={2020},
    eprint={2001.05566},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@inproceedings{AlexNet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}

@misc{1409.1556,
    Author = {Karen Simonyan and Andrew Zisserman},
    Title = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
    Year = {2014},
    Eprint = {arXiv:1409.1556},
}

@article{U-net,
    author    = {Olaf Ronneberger and
               Philipp Fischer and
               Thomas Brox},
    title     = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
    journal   = {CoRR},
    volume    = {abs/1505.04597},
    year      = {2015},
    url       = {http://arxiv.org/abs/1505.04597},
    archivePrefix = {arXiv},
    eprint    = {1505.04597},
    timestamp = {Mon, 13 Aug 2018 16:46:52 +0200},
    biburl    = {https://dblp.org/rec/journals/corr/RonnebergerFB15.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{LSTM,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@article{Cityscapes,
    author    = {Marius Cordts and
               Mohamed Omran and
               Sebastian Ramos and
               Timo Rehfeld and
               Markus Enzweiler and
               Rodrigo Benenson and
               Uwe Franke and
               Stefan Roth and
               Bernt Schiele},
    title     = {The Cityscapes Dataset for Semantic Urban Scene Understanding},
    journal   = {CoRR},
    volume    = {abs/1604.01685},
    year      = {2016},
    url       = {http://arxiv.org/abs/1604.01685},
    archivePrefix = {arXiv},
    eprint    = {1604.01685},
    timestamp = {Mon, 13 Aug 2018 16:47:48 +0200},
    biburl    = {https://dblp.org/rec/journals/corr/CordtsORREBFRS16.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{PASCAL,
    title={The pascal visual object classes (voc) challenge},
    author={Everingham, Mark and Van Gool, Luc and Williams, Christopher KI and Winn, John and Zisserman, Andrew},
    journal={International journal of computer vision},
    volume={88},
    number={2},
    pages={303--338},
    year={2010},
    publisher={Springer}
}

@misc{repo,
    author = {d'Agostino, Alessandro},
    title = {Dataset Generation for the Training of Neural Networks Oriented toward Histological Image Segmentation},
    year = {2020},
    month = {april},
    url = {\url{https://github.com/AlessandrodAgostino/Thesys-Project}}
}

@InProceedings{10.1007/BFb0031048,
    author="Brockett, R. W.",
    editor="Fuhrmann, P. A.",
    title="Robotic manipulators and the product of exponentials formula",
    booktitle="Mathematical Theory of Networks and Systems",
    year="1984",
    publisher="Springer Berlin Heidelberg",
    address="Berlin, Heidelberg",
    pages="120--129",
    abstract="The manipulation of rigid bodies by manipulators which are motor driven kinematic chains is a fundamental aspect of robotics. In this paper, we discuss the kinematics of such processes and discuss the classification of kinematic chains using ideas from algebra and group theory. Earlier work on the role of Lie groups in mechanisms is contained in Herv{\'e} [7], but the role of Lie algebras is not considered by this author. More relevant (but less group theoretic) is the extensive case-by-case analysis found in Pieper's thesis [9]. In fact, Pieper's work suggests an interesting and rather general problem in Galois theory which is directly related to manipulation. Also of interest is the well-known Baker-Campbell-Hausdorff formula for the derivative of a product of exponentials since such products are of fundamental importance in the study of kinematic programming.",
    isbn="978-3-540-38826-5"
}

@article{lindenmayer1968mathematical,
    title={Mathematical models for cellular interactions in development II. Simple and branching filaments with two-sided inputs},
    author={Lindenmayer, Aristid},
    journal={Journal of theoretical biology},
    volume={18},
    number={3},
    pages={300--315},
    year={1968},
    publisher={Elsevier}
}

@article{VoronoiNouvellesAD,
    title={Nouvelles applications des param{\`e}tres continus {\`a} la th{\'e}orie des formes quadratiques. Premier m{\'e}moire. Sur quelques propri{\'e}t{\'e}s des formes quadratiques positives parfaites.},
    author={Georges Voronoi},
    journal={Journal f{\"u}r die reine und angewandte Mathematik (Crelles Journal)},
    volume={1908},
    pages={102 - 97}
}

@article{ALSAYEDNOOR201644,
    title = "Evaluating the performance of microstructure generation algorithms for 2-d foam-like representative volume elements",
    journal = "Mechanics of Materials",
    volume = "98",
    pages = "44 - 58",
    year = "2016",
    issn = "0167-6636",
    doi = "https://doi.org/10.1016/j.mechmat.2016.04.001",
    url = "http://www.sciencedirect.com/science/article/pii/S016766361630028X",
    author = "J. Alsayednoor and P. Harrison",
    keywords = "Anisotropy, Foam, Micro-macro, RVE, Periodic",
    abstract = "This investigation evaluates various numerical algorithms; each designed to generate periodic 2-D Representative Volume Elements (RVEs) containing foam-like microstructures suitable for direct import into commercial finite element software for mechanical evaluation. The operation of each algorithm is discussed and the resulting RVEs are examined from both a mechanical and a morphological perspective. A basic Voronoi-based algorithm is found to be simple to implement but the method is shown to produce inherently anisotropic microstructures. Increasing the degree of irregularity of the microstructure reduces the anisotropy but at the cost of creating unrealistic microstructures, containing highly angular cells. A method of modifying such unrealistic microstructures using a centroidal tessellation relaxation algorithm is demonstrated, ultimately producing RVEs with relatively realistic mono-disperse microstructures. An alternative algorithm is also investigated the advantage of this algorithm is its ability to generate poly-disperse microstructures, with a controllable degree of poly-dispersity and an almost fully isotropic mechanical response."
}

@article{SOBOL2001271,
    title = "Global sensitivity indices for nonlinear mathematical models and their Monte Carlo estimates",
    journal = "Mathematics and Computers in Simulation",
    volume = "55",
    number = "1",
    pages = "271 - 280",
    year = "2001",
    note = "The Second IMACS Seminar on Monte Carlo Methods",
    issn = "0378-4754",
    doi = "https://doi.org/10.1016/S0378-4754(00)00270-6",
    url = "http://www.sciencedirect.com/science/article/pii/S0378475400002706",
    author = "I.M Sobol′",
    keywords = "Sensitivity analysis, Monte Carlo method, Quasi-Monte Carlo method, Mathematical modelling",
    abstract = "Global sensitivity indices for rather complex mathematical models can be efficiently computed by Monte Carlo (or quasi-Monte Carlo) methods. These indices are used for estimating the influence of individual variables or groups of variables on the model output."
}

@article{SOBOL1976236,
    title = "Uniformly distributed sequences with an additional uniform property",
    journal = "USSR Computational Mathematics and Mathematical Physics",
    volume = "16",
    number = "5",
    pages = "236 - 242",
    year = "1976",
    issn = "0041-5553",
    doi = "https://doi.org/10.1016/0041-5553(76)90154-3",
    url = "http://www.sciencedirect.com/science/article/pii/0041555376901543",
    author = "I.M. Sobol"
}

@article{SALTELLI2002280,
    title = "Making best use of model evaluations to compute sensitivity indices",
    journal = "Computer Physics Communications",
    volume = "145",
    number = "2",
    pages = "280 - 297",
    year = "2002",
    issn = "0010-4655",
    doi = "https://doi.org/10.1016/S0010-4655(02)00280-1",
    url = "http://www.sciencedirect.com/science/article/pii/S0010465502002801",
    author = "Andrea Saltelli",
    keywords = "Sensitivity analysis, Sensitivity measures, Sensitivity indices, Importance measures",
    abstract = "This paper deals with computations of sensitivity indices in sensitivity analysis. Given a mathematical or computational model y=f(x1,x2,…,xk), where the input factors xi's are uncorrelated with one another, one can see y as the realization of a stochastic process obtained by sampling each of the xi from its marginal distribution. The sensitivity indices are related to the decomposition of the variance of y into terms either due to each xi taken singularly (first order indices), as well as into terms due to the cooperative effects of more than one xi. In this paper we assume that one has computed the full set of first order sensitivity indices as well as the full set of total-order sensitivity indices (a fairly common strategy in sensitivity analysis), and show that in this case the same set of model evaluations can be used to compute double estimates of: &#x02022;the total effect of two factors taken together, for all such k2 couples, where k is the dimensionality of the model;&#x02022;the total effect of k−2 factors taken together, for all k2 such (k−2) ples. We further introduce a new strategy for the computation of the full sets of first plus total order sensitivity indices that is about 50% cheaper in terms of model evaluations with respect to previously published works. We discuss separately the case where the input factors xi's are not independent from each other."
}

@article{SALTELLI2010259,
    title = "Variance based sensitivity analysis of model output. Design and estimator for the total sensitivity index",
    journal = "Computer Physics Communications",
    volume = "181",
    number = "2",
    pages = "259 - 270",
    year = "2010",
    issn = "0010-4655",
    doi = "https://doi.org/10.1016/j.cpc.2009.09.018",
    url = "http://www.sciencedirect.com/science/article/pii/S0010465509003087",
    author = "Andrea Saltelli and Paola Annoni and Ivano Azzini and Francesca Campolongo and Marco Ratto and Stefano Tarantola",
    abstract = "Variance based methods have assessed themselves as versatile and effective among the various available techniques for sensitivity analysis of model output. Practitioners can in principle describe the sensitivity pattern of a model Y=f(X1,X2,…,Xk) with k uncertain input factors via a full decomposition of the variance V of Y into terms depending on the factors and their interactions. More often practitioners are satisfied with computing just k first order effects and k total effects, the latter describing synthetically interactions among input factors. In sensitivity analysis a key concern is the computational cost of the analysis, defined in terms of number of evaluations of f(X1,X2,…,Xk) needed to complete the analysis, as f(X1,X2,…,Xk) is often in the form of a numerical model which may take long processing time. While the computational cost is relatively cheap and weakly dependent on k for estimating first order effects, it remains expensive and strictly k-dependent for total effect indices. In the present note we compare existing and new practices for this index and offer recommendations on which to use."
}
